{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "colab_type": "code",
        "id": "WTNXOcw6EOsH",
        "outputId": "951eff3d-05fd-49ff-878c-7300e5bff61e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "colab_type": "code",
        "id": "Adac0OfZFeZf",
        "outputId": "fbd436eb-fd0e-45ad-f159-595b3749c5d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-71e12f4bac70>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ]
        }
      ],
      "source": [
        "mnist = input_data.read_data_sets('data', one_hot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "colab_type": "code",
        "id": "-tAA-34HKwDd",
        "outputId": "d7918a2b-f437-45fd-d613-0c96975541d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 epoch, test acc is 0.824600\n",
            "1 epoch, test acc is 0.892100\n",
            "2 epoch, test acc is 0.901700\n",
            "3 epoch, test acc is 0.906600\n",
            "4 epoch, test acc is 0.908000\n",
            "5 epoch, test acc is 0.910300\n",
            "6 epoch, test acc is 0.911800\n",
            "7 epoch, test acc is 0.913100\n",
            "8 epoch, test acc is 0.915400\n",
            "9 epoch, test acc is 0.916500\n",
            "10 epoch, test acc is 0.917400\n",
            "11 epoch, test acc is 0.917800\n",
            "12 epoch, test acc is 0.918800\n",
            "13 epoch, test acc is 0.920400\n",
            "14 epoch, test acc is 0.919500\n",
            "15 epoch, test acc is 0.920200\n",
            "16 epoch, test acc is 0.920400\n",
            "17 epoch, test acc is 0.921000\n",
            "18 epoch, test acc is 0.919900\n",
            "19 epoch, test acc is 0.921400\n"
          ]
        }
      ],
      "source": [
        "batch_size = 100\n",
        "m_batch = mnist.train.num_examples // batch_size\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "w = tf.Variable(tf.zeros(shape=[784, 10]))\n",
        "b = tf.Variable(tf.zeros(shape=[10]))\n",
        "\n",
        "prediction = tf.nn.softmax(tf.matmul(x, w) + b)\n",
        "\n",
        "#loss = tf.reduce_mean(tf.square(y-prediction))\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
        "\n",
        "train = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "correct_predict = tf.equal(tf.argmax(y, axis=1), tf.argmax(prediction, axis=1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(20):\n",
        "    for batch in range(m_batch):\n",
        "      batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "      sess.run(train, feed_dict={x:batch_xs, y:batch_ys})\n",
        "    acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
        "    print('%d epoch, test acc is %f' % (epoch, acc))"
      ]
    }
  ]
}